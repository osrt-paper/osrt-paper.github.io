<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport"
          content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description"
          content="Object Scene Representation Transformer">
    <meta name="author"
          content="Mehdi S. M. Sajjadi, Daniel Duckworth, Aravindh Mahendran, Sjoerd van Steenkiste, Filip Pavetic, Mario Lucic, Leonidas J. Guibas, Klaus Greff, Thomas Kipf">
    <link rel="stylesheet"
          href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css"
          integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk"
          crossorigin="anonymous">
    <title>Object Scene Representation Transformer</title>
    <style>
      h2 {
        text-align: center;
      }
      .paper-title {
        margin-top: 2em;
        margin-bottom: 2em;
      }
      .authors-list .name {
        font-size: 1.2em;
        margin-bottom: 0.5em;
      }
      .paper-link a {
        font-size: 1em;
      }
      .neg-space {
        margin-top: -1.3em;
      }
      .teaser-image {
        padding-left: 5%;
        padding-right: 5%;
        margin-bottom: 2em;
      }
      .msn-video::before {
        padding-top: 40%;
      }
      .content-block {
        padding-left: .5em;
        padding-right: .5em;
        padding-bottom: 2em;
      }
      .col-md {
        margin-bottom: 1em;
      }
      .citation .description {
        font-family: "Courier", monospace;
        font-size: 16px;
        white-space: pre;
        text-align: left;
        padding-left: 10%;
      }
      .footnote {
        background-color: #e9ecef;
        padding-top: 1em;
        padding-bottom: 1em;
      }
    </style>
  </head>

  <body>
    <div class="jumbotron jumbotron-fluid overflow-auto">

      <!-- Title -->
      <div class="paper-title">
        <h1 class="name text-center">Object Scene Representation Transformer</h1>
      </div>

      <!-- Authors -->
      <div class="authors-list">
        <p class="name text-center">
          <a href="https://msajjadi.com/" target="_blank">Mehdi S. M. Sajjadi</a>‡,&nbsp;
          <a href="https://www.stronglyconvex.com/about.html" target="_blank">Daniel Duckworth</a>*,&nbsp;
          <a href="https://aravindhm.github.io/" target="_blank">Aravindh Mahendran</a>*,&nbsp;
          <a href="https://www.sjoerdvansteenkiste.com/" target="_blank">Sjoerd van Steenkiste</a>*,<br>
          <a href="https://www.linkedin.com/in/filip-pavetic/" target="_blank">Filip Pavetić</a>,&nbsp;
          <a href="https://lucic.ai/" target="_blank">Mario Lučić</a>,&nbsp;
          <a href="https://profiles.stanford.edu/leonidas-guibas" target="_blank">Leonidas J. Guibas</a>,&nbsp;
          <a href="https://qwlouse.github.io/" target="_blank">Klaus Greff</a>,&nbsp;
          <a href="https://tkipf.github.io/" target="_blank">Thomas Kipf</a>*
          <br><br>
          <img src="data/google-research-logo.svg" alt="Google Research" width="150em"/>
        </p>
        <p class="text-center text-secondary">
          <small>
          ‡correspondence to: <a href="mailto:osrt@msajjadi.com">osrt@msajjadi.com</a>
          <br>
          *equal technical contribution</p>
          </small>
      </div>

      <!-- Paper link -->
      <div class="paper-link">
        <p class="text-center">
          <a class="btn btn-primary" href="https://arxiv.org/abs/2206.06922" target="_blank">Paper</a>
        </p>
      </div>
    </div>

    <div class="container">
      <div class="row">
        <div class="col embed-responsive teaser-image">
          <img src="data/osrt.png" style="width: 100%; object-fit: contain" />
        </div>
      </div>
      <div class="row">
        <div class="col">
          <p class="text-center text-secondary neg-space">
            <i>Figure</i>: OSRT is a 3D scene representation learning method that decomposes scenes into individual objects without supervision.
          </p>
        </div>
      </div>


      <div class="content-block">
        <div class="row">
          <div class="col">
            <p class="description">
              A compositional understanding of the world in terms of objects and their geometry in 3D space is considered a cornerstone of human cognition. Facilitating the learning of such a representation in neural networks holds promise for substantially improving labeled data efficiency. As a key step in this direction, we make progress on the problem of learning 3D-consistent decompositions of complex scenes into individual objects in an unsupervised fashion. We introduce <i>Object Scene Representation Transformer (OSRT)</i>, a 3D-centric model in which individual object representations naturally emerge through novel view synthesis. OSRT scales to significantly more complex scenes with larger diversity of objects and backgrounds than existing methods. At the same time, it is multiple orders of magnitude faster at compositional rendering thanks to its light field parametrization and the novel <i>Slot Mixer</i> decoder. We believe this work will not only accelerate future architecture exploration and scaling efforts, but it will also serve as a useful tool for both object-centric as well as neural scene representation learning communities.
            </p>
          </div>
        </div>
      </div>

      <div class="content-block">
        <div class="row">
          <div class="col">
            <h2>Qualitative Results</h2>
            <hr />
            <p class="description">
              OSRT is able to learn object-decomposed 3D scene representations without supervision on complex multi-object scenes with a large variety of objects and textured backgrounds. Below, we show example qualitative results on 3D scenes not seen during model training.
            </p>
          </div>
        </div>
        <div class="row">

          <div class="col-md">
            <div class="row">
              <div class="col embed-responsive msn-video">
                <video muted autoplay loop playsinline>
                  <source src="data/osrt_results_1.mp4" type="video/mp4">
                  Sorry, your browser doesn't support embedded videos.
                </video>
              </div>
            </div>
          </div>

          <div class="col-md">
            <div class="row">
              <div class="col embed-responsive msn-video">
                <video muted autoplay loop playsinline>
                  <source src="data/osrt_results_2.mp4" type="video/mp4">
                  Sorry, your browser doesn't support embedded videos.
                </video>
              </div>
            </div>
          </div>
        </div>

        <div class="row">

          <div class="col-md">
            <div class="row">
              <div class="col embed-responsive msn-video">
                <video muted autoplay loop playsinline>
                  <source src="data/osrt_results_3.mp4" type="video/mp4">
                  Sorry, your browser doesn't support embedded videos.
                </video>
              </div>
            </div>
          </div>

          <div class="col-md">
            <div class="row">
              <div class="col embed-responsive msn-video">
                <video muted autoplay loop playsinline>
                  <source src="data/osrt_results_4.mp4" type="video/mp4">
                  Sorry, your browser doesn't support embedded videos.
                </video>
              </div>
            </div>
          </div>
        </div>


        <div class="row">
          <div class="col">
            <p class="text-center text-secondary"><i>Figure</i>: Qualitative scene decomposition and novel view synthesis results on unseen 3D scenes.
          </div>
        </div>
      </div>



      <!-- Related Projects -->
      <div class="content-block citation">
        <div class="row">
          <div class="col">
            <h2>Related Projects</h2>
            <hr />
          <a href="https://srt-paper.github.io/" target="_blank">Scene Representation Transformer (SRT)</a>
          <br>
          <a href="https://github.com/google-research/google-research/tree/master/slot_attention" target="_blank">Slot Attention</a>
          </div>
        </div>
      </div>




      <!-- Citation -->
      <div class="content-block citation">
        <div class="row">
          <div class="col">
            <h2>Reference</h2>
            <hr />
            <p class="description overflow-auto">
    @article{sajjadi2022osrt,
      author = {Sajjadi, Mehdi S. M.
                and Duckworth, Daniel
                and van Steenkiste, Sjoerd
                and Mahendran, Aravindh
                and Pavetic, Filip
                and Lucic, Mario
                and Guibas, Leonidas J.
                and Greff, Klaus
                and Kipf, Thomas
                },
      title = {{Object Scene Representation Transformer}},
      journal = {arXiv preprint arXiv:2206.06922},
      year  = {2022}
    }</p>
          </div>
        </div>
      </div>
    </div>



    <div class="footnote">
      <div class="container">
      </div>
    </div>

    <!-- Bootstrap -->
    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"
            integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"
            crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
            integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
            crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js"
            integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI"
            crossorigin="anonymous"></script>
  </body>
</html>
